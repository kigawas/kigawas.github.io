<!doctype html><html lang=en><head><title>Reconsider the performance benchmarks in Python web development :: map(learn, world)</title>
<meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A few words on common misunderstandings and performance tips of web development benchmarks.
Overview As of 2020, amongst the various web benchmarks, the most prestigious and reliable one would be TechEmpower benchmarks. Despite the fact that asyncio-based web frameworks prevail on performance in theory and in practice, how performant those frameworks are in pragmatic environments remains to be inspected.
According to TechEmpower benchmarks, it can be noticed that some Python frameworks even outperform Gin, the most famous and widely used Go web framework."><meta name=keywords content><meta name=robots content="noodp"><link rel=canonical href=/posts/performance-benchmarks-in-python-web-development/><link rel=stylesheet href=/assets/style.css><link rel=stylesheet href=/assets/blue.css><link rel=apple-touch-icon href=/img/apple-touch-icon-192x192.png><link rel="shortcut icon" href=/favicon.ico><meta name=twitter:card content="summary"><meta name=twitter:site content><meta name=twitter:creator content><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="og:title" content="Reconsider the performance benchmarks in Python web development"><meta property="og:description" content="A few words on common misunderstandings and performance tips of web development benchmarks"><meta property="og:url" content="/posts/performance-benchmarks-in-python-web-development/"><meta property="og:site_name" content="map(learn, world)"><meta property="og:image" content="/"><meta property="og:image:width" content="2048"><meta property="og:image:height" content="1024"><meta property="article:published_time" content="2020-11-12 00:00:00 +0000 UTC"></head><body class=blue><div class="container center headings--one-size"><header class=header><div class=header__inner><div class=header__logo><a href=/><div class=logo>map(learn, world)</div></a></div><div class=menu-trigger>menu</div></div><nav class=menu><ul class="menu__inner menu__inner--desktop"><li><a href=/about>About</a></li><li><a href=/projects>Projects</a></li></ul><ul class="menu__inner menu__inner--mobile"><li><a href=/about>About</a></li><li><a href=/projects>Projects</a></li></ul></nav></header><div class=content><div class=post><h1 class=post-title><a href=/posts/performance-benchmarks-in-python-web-development/>Reconsider the performance benchmarks in Python web development</a></h1><div class=post-meta><span class=post-date>2020-11-12 [Updated: 2020-12-21]</span></div><span class=post-tags>#<a href=/tags/python/>Python</a>&nbsp;
#<a href=/tags/web/>web</a>&nbsp;
#<a href=/tags/fastapi/>FastAPI</a>&nbsp;
#<a href=/tags/sanic/>Sanic</a>&nbsp;
#<a href=/tags/golang/>Golang</a>&nbsp;
#<a href=/tags/benchmark/>benchmark</a>&nbsp;</span><div class=post-content><div><p>A few words on common misunderstandings and performance tips of web development benchmarks.</p><h2 id=overview>Overview<a href=#overview class=hanchor arialabel=Anchor>&#8983;</a></h2><p>As of 2020, amongst the various web benchmarks, the most prestigious and reliable one would be <a href="https://www.techempower.com/benchmarks/#section=data-r19&hw=cl&test=fortune&l=zijzen-1r">TechEmpower benchmarks</a>. Despite the fact that <a href=https://docs.python.org/3/library/asyncio.html>asyncio</a>-based web frameworks prevail on performance in theory and in practice, <strong>how</strong> performant those frameworks are in pragmatic environments remains to be inspected.</p><p>According to TechEmpower benchmarks, it can be noticed that some Python frameworks even <a href="https://www.techempower.com/benchmarks/#section=data-r19&hw=ph&test=fortune&l=zijmrj-1r">outperform Gin</a>, the most famous and widely used Go web framework. In this article, some practical experiments will be carried out over the issue.</p><h2 id=common-misunderstandings>Common misunderstandings<a href=#common-misunderstandings class=hanchor arialabel=Anchor>&#8983;</a></h2><h3 id=probable-misuse-of-the-word-_performance_>Probable misuse of the word <em>performance</em><a href=#probable-misuse-of-the-word-_performance_ class=hanchor arialabel=Anchor>&#8983;</a></h3><p>The following claims are usually found on most web frameworks:</p><blockquote><p>It features a Martini-like API with much better performance &ndash; up to 40 times faster. &ndash; <em>Gin</em>, 2020</p><p>Fast and unfancy HTTP server framework for Go (Golang). Up to 10x faster than the rest. &ndash; <em>Echo</em>, before 2017</p><p>High performance, extensible, minimalist Go web framework. &ndash; <em>Echo</em>, 2020</p><p>Screaming-fast Python 3.5+ HTTP toolkit integrated with pipelining HTTP server based on uvloop and picohttpparser. &ndash; <em>Japronto</em>, 2020</p></blockquote><p>Let&rsquo;s ponder: what do they mean &ldquo;fast&rdquo; or &ldquo;high performance&rdquo;? Handling one request in very short time? Or handling <strong>more</strong> requests per second? Unfortunately, I don&rsquo;t think those developers share one understanding on &ldquo;performance&rdquo;, but here let&rsquo;s clarify:</p><p>More requests per second, more performant. A more formal definition would be: more requests/responses per second, or RPS, means higher performance.</p><h3 id=asyncio-does-not-improve-speed-but-it-does-improve-throughput><code>asyncio</code> does not improve speed, but it does improve throughput<a href=#asyncio-does-not-improve-speed-but-it-does-improve-throughput class=hanchor arialabel=Anchor>&#8983;</a></h3><p>The assumption that <code>asyncio</code> or <a href=https://www.python.org/dev/peps/pep-0492/>coroutines</a> can speed up Python programs is a common fallacy. <strong>Asynchrony</strong> is guaranteed instead.</p><p>The following facts have to be revisited before getting into an example:</p><blockquote><p>Synchrony/asynchrony and blocking/non-blocking are orthogonal concepts.</p><p>Blocking IO can still be used in an asynchronous coroutine. A more realistic example should be reading files synchronously from hard disks in asynchronous programs.</p><p>Coroutines are special (asynchronous) functions, which can be paused and resumed without losing their current states by some supervisor, or &ldquo;event loop&rdquo;. In Python 3.5 and before, coroutines were implemented by generators.</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>test</span>():
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;before 1&#34;</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>await</span> coro1()
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;after 1&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;before 2&#34;</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>await</span> coro2()
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;after 2&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#34;result&#34;</span>
</span></span></code></pre></div><p>The <code>test</code> coroutine runs 10 times, numbered as <code>test_1</code> &mldr; <code>test_10</code>, with the following simplified scenario:</p><ol><li><code>test_1</code> awaits some time-consuming <code>coro1</code></li><li><code>test_2</code> is called and also awaits <code>coro1</code></li><li><code>await coro1()</code> in <code>test_1</code> returns</li><li><code>test_1</code> resumes</li></ol><blockquote><p>For more details, keep the <a href=https://docs.python.org/3/library/asyncio.html>official documentation</a> under your pillow.</p></blockquote><p>If <code>test</code> is just invoked once, using <code>asyncio</code> costs more computing resources because of excessive event loops and schedulers under the hood. But thankfully the functions to handle HTTP requests are invoked repeatedly as <code>test</code>. These functions probably spend more time on interacting with a database.</p><p>An interface between web servers and frameworks called <a href=https://asgi.readthedocs.io/en/latest/introduction.html>ASGI</a> adopts this idea:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>application</span>(scope, receive, send):
</span></span><span style=display:flex><span>    event <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> receive()
</span></span><span style=display:flex><span>    data <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> read_data_from_db()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>await</span> send({<span style=color:#e6db74>&#34;type&#34;</span>: <span style=color:#e6db74>&#34;websocket.send&#34;</span>, <span style=color:#f92672>...</span>})
</span></span></code></pre></div><p>The coroutine <code>receive</code> transforms HTTP requests into Python dictionaries such as:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;type&#34;</span>: <span style=color:#e6db74>&#34;http.request&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;body&#34;</span>: <span style=color:#e6db74>b</span><span style=color:#e6db74>&#34;Hello World&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;more_body&#34;</span>: <span style=color:#66d9ef>False</span>,
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Calling the coroutine by <code>await send(...)</code> will send the response to client, as imagined, the coroutine <code>application</code> is called every time when there comes a request from a client.</p><p>It&rsquo;s confident to say web servers handle more requests with <code>asyncio</code>, but it cannot speed up one request - in effect, it gets slightly <strong>slower in each request</strong>.</p><h2 id=tips-on-performance-and-benchmarks>Tips on performance and benchmarks<a href=#tips-on-performance-and-benchmarks class=hanchor arialabel=Anchor>&#8983;</a></h2><h3 id=uvloop-is-dope><code>uvloop</code> is dope<a href=#uvloop-is-dope class=hanchor arialabel=Anchor>&#8983;</a></h3><p>The standard library <code>asyncio</code> helps, but actually it&rsquo;s just a <a href=https://www.python.org/dev/peps/pep-3156/>reference implementation</a>. By leveraging <a href=https://github.com/cython/cython><code>Cython</code></a> and <a href=https://github.com/libuv/libuv><code>libuv</code></a>, <a href=https://github.com/MagicStack>MagicStack</a> implemented a faster event loop called <code>uvloop</code>:</p><p><img alt="uvloop performance" src=https://raw.githubusercontent.com/MagicStack/uvloop/master/performance.png></p><p>Based on <code>uvloop</code>, a fast ASGI server implementation called <a href=https://github.com/encode/uvicorn><code>uvicorn</code></a> is the de facto server adopted by most asynchronous web frameworks in Python.</p><h3 id=more-than-hello-world-json-benchmarks>More than &ldquo;Hello world&rdquo; JSON benchmarks<a href=#more-than-hello-world-json-benchmarks class=hanchor arialabel=Anchor>&#8983;</a></h3><p>Most benchmarks are focusing two aspects mainly: JSON serialization and database read/write. JSON serialization is typically a CPU-bound task in contrast database r/w is an IO-bound task. Often this JSON is:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{ <span style=color:#f92672>&#34;message&#34;</span>: <span style=color:#e6db74>&#34;Hello, World!&#34;</span> }
</span></span></code></pre></div><p>With Bottle/Flask-like styles, routes are defined like:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> awesome_framework <span style=color:#f92672>import</span> JSONResponse, App
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>app <span style=color:#f92672>=</span> App()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>@app.get</span>(<span style=color:#e6db74>&#34;/&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>handler</span>():
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> JSONResponse(dict(message<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Hello, world!&#34;</span>))  <span style=color:#75715e># an explicit JSON serialization pattern</span>
</span></span></code></pre></div><p>Limited to JSON serialization, <a href=https://github.com/squeaky-pl/japronto>Japronto</a> has incredible performance: <a href="https://www.techempower.com/benchmarks/#section=data-r19&hw=cl&test=json&l=zijmrj-1r">133859 RPS on Azure D3v2 instances</a> and this is twice Gin or Beego written in Golang.</p><p>A Python novice may be excited, but veterans will inspect again: What is the approximate percentage of JSON serialization in our &ldquo;yet another awesome web service&rdquo;? Can it be profiled?</p><p>Probably the percentage is pretty low, in fact, the most time-consuming task would be connecting the database, retrieving or updating data and close the connection. And the network-IO eats most of time, no matter how fast JSON serialization is.</p><blockquote><p>No one refuses better performance. To attain extreme JSON serialization speed in Python, check <a href=https://github.com/ijl/orjson><code>orjson</code></a>.</p></blockquote><h3 id=orm-is-more-practical>ORM is more practical<a href=#orm-is-more-practical class=hanchor arialabel=Anchor>&#8983;</a></h3><p>In a more practical scenario, it&rsquo;s necessary to integrate some ORM into the web framework. There are also abundant async or sync ORMs in Python community, such as:</p><ul><li><a href=https://github.com/python-gino/gino>gino</a>, async</li><li><a href=https://github.com/encode/orm>orm</a>, async</li><li><a href=https://github.com/tortoise/tortoise-orm/>tortoise-orm</a>, async</li><li><a href=https://docs.sqlalchemy.org/en/14/>SQLAlchemy</a>, async and sync</li><li><a href=https://docs.djangoproject.com/en/3.1/topics/db/>Django ORM</a>, sync</li><li><a href=https://github.com/ponyorm/pony>Pony ORM</a>, sync</li></ul><p>Query expressions are similar among ORMs:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>User</span>(Model):
</span></span><span style=display:flex><span>    id <span style=color:#f92672>=</span> Column(Integer, primary_key<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>    name <span style=color:#f92672>=</span> Column(String)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>@classmethod</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_user_by_name</span>(cls, name: str):
</span></span><span style=display:flex><span>        <span style=color:#75715e># in async orm</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>await</span> cls<span style=color:#f92672>.</span>filter<span style=color:#f92672>.</span>where(name<span style=color:#f92672>=</span>name)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>@classmethod</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_users</span>(cls):
</span></span><span style=display:flex><span>        <span style=color:#75715e># in sync orm</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> cls<span style=color:#f92672>.</span>filter<span style=color:#f92672>.</span>all()
</span></span></code></pre></div><p>When they get invoked, ORM does the hardest task: converting the query expressions to raw SQLs. As you know, this is pretty sluggish and hurts performance badly, especially in Python.</p><blockquote><p>I didn&rsquo;t test very rigorously, but it may slow the server by 30% approximately.</p></blockquote><p>If ORM is so slow, what about writing raw SQLs directly?</p><h3 id=raw-sqls-outperform-orm-but-orms-are-more-common>Raw SQLs outperform ORM, but ORMs are more common<a href=#raw-sqls-outperform-orm-but-orms-are-more-common class=hanchor arialabel=Anchor>&#8983;</a></h3><p>In Python community, most popular database clients are just a thin wrapper over some C implementation, such as <code>psycopg2</code>/<code>psycopg2-binary</code> for PostgreSQL or <code>mysqlclient</code> for MySQL. Prevalent reasons include efficiency, security, code reuse, etc.</p><p>However, in asynchronous Python, there is another story. Connecting a database is mainly about setting up a TCP socket, sending some binary data and getting the response, with some additional concurrent connections in a pool. This is akin to what has been discussed above - an HTTP server.</p><p>What if <code>uvloop</code> is introduced into database connectors just like <code>ASGI</code>? Well, we are not the first to come up with this notion and there already exists a PostgreSQL connector called <code>asyncpg</code>.</p><blockquote><p>MagicStack is also the author of <code>asyncpg</code>.</p></blockquote><p><code>asyncpg</code> has an astonishing performance:</p><p><img alt="asyncpg performance" src=https://raw.githubusercontent.com/MagicStack/asyncpg/master/performance.png></p><p>For <a href=http://magic.io/blog/asyncpg-1m-rows-from-postgres-to-python/>how</a> did they achieve this:</p><blockquote><p>It soon became evident that by implementing PostgreSQL frontend/backend protocol directly, we can yield significant speed improvements. Our earlier experience with uvloop has shown that Cython can be used to build very efficient libraries. asyncpg is written almost entirely in Cython with careful buffer management and highly optimized data decoding pipeline.</p></blockquote><p>Most benchmarks are combining web frameworks with database connectors and performance are tested by executing raw SQLs instead of ORM queries.</p><p>This looks okay, but to what extent are we writing raw SQLs and getting them executed in a connector? At least for me, I only write raw SQLs in ORM <strong>only</strong> when there are performance problems to resolve, but in most cases, something like <code>cls.filter.where(name=name)</code> is way more familiar.</p><p>Everyone blames ORM when they get into performance trouble. Is there any method to get performant as promised in the <code>benchmarks.md</code>?</p><h3 id=baked-queries>Baked queries<a href=#baked-queries class=hanchor arialabel=Anchor>&#8983;</a></h3><p>As mentioned above, converting an ORM query to its corresponding SQL costs considerable time. According to the <a href=https://en.wikipedia.org/wiki/Pareto_principle>Pareto principle</a>, we normally spend most of time on a few queries, thus, it&rsquo;s a natural intuition to <strong>cache those queries</strong> instead of parsing ORM queries to SQLs over again.</p><blockquote><p>The cached queries are called <a href=https://docs.sqlalchemy.org/en/13/orm/extensions/baked.html>baked queries</a>.</p><p>This technique is different from caching the results from database - you only cache the generated SQLs so there is no need to worry about the consistency.</p></blockquote><p>Below is an example from <a href=https://python-gino.org/docs/en/master/how-to/bakery.html>gino</a>.</p><blockquote><p>Gino is an async ORM based on <a href=https://docs.sqlalchemy.org/en/13/core/>SQLAlchemy Core</a> and <code>asyncpg</code> with rather decent usability and performance.</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>User</span>(db<span style=color:#f92672>.</span>Model):
</span></span><span style=display:flex><span>    __tablename__ <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;users&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    id <span style=color:#f92672>=</span> db<span style=color:#f92672>.</span>Column(db<span style=color:#f92672>.</span>Integer, primary_key<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>    name <span style=color:#f92672>=</span> db<span style=color:#f92672>.</span>Column(db<span style=color:#f92672>.</span>String)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>@db.bake</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>getter</span>(cls):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> cls<span style=color:#f92672>.</span>query<span style=color:#f92672>.</span>where(cls<span style=color:#f92672>.</span>id <span style=color:#f92672>==</span> db<span style=color:#f92672>.</span>bindparam(<span style=color:#e6db74>&#34;uid&#34;</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>@classmethod</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_by_id</span>(cls, uid: int):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>await</span> cls<span style=color:#f92672>.</span>getter<span style=color:#f92672>.</span>one_or_none(uid<span style=color:#f92672>=</span>uid)
</span></span></code></pre></div><p>With baked queries, you can get around the main bottleneck of parsing ORM queries into SQLs, in most cases this would be a huge performance enhancement:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ wrk --latency -t20 -c50 -d15s http://0.0.0.0:8080/api/users/1  <span style=color:#75715e># pure ORM</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Running 15s test @ http://0.0.0.0:8080/api/users/1
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>20</span> threads and <span style=color:#ae81ff>50</span> connections
</span></span><span style=display:flex><span>  Thread Stats   Avg      Stdev     Max   +/- Stdev
</span></span><span style=display:flex><span>    Latency    12.57ms    8.38ms 178.15ms   76.60%
</span></span><span style=display:flex><span>    Req/Sec   165.40     79.13   440.00     82.63%
</span></span><span style=display:flex><span>  Latency Distribution
</span></span><span style=display:flex><span>     50%   12.12ms
</span></span><span style=display:flex><span>     75%   16.06ms
</span></span><span style=display:flex><span>     90%   19.62ms
</span></span><span style=display:flex><span>     99%   39.17ms
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>49473</span> requests in 15.06s, 7.03MB read
</span></span><span style=display:flex><span>Requests/sec:   3284.77
</span></span><span style=display:flex><span>Transfer/sec:    477.96KB
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ wrk --latency -t20 -c50 -d15s http://0.0.0.0:8080/api/users/1/bake  <span style=color:#75715e># with baked queries</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Running 15s test @ http://0.0.0.0:8080/api/users/1/bake
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>20</span> threads and <span style=color:#ae81ff>50</span> connections
</span></span><span style=display:flex><span>  Thread Stats   Avg      Stdev     Max   +/- Stdev
</span></span><span style=display:flex><span>    Latency    10.53ms   10.43ms 156.56ms   96.66%
</span></span><span style=display:flex><span>    Req/Sec   211.44     69.41   560.00     76.27%
</span></span><span style=display:flex><span>  Latency Distribution
</span></span><span style=display:flex><span>     50%    9.07ms
</span></span><span style=display:flex><span>     75%   11.34ms
</span></span><span style=display:flex><span>     90%   14.57ms
</span></span><span style=display:flex><span>     99%   61.73ms
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>63338</span> requests in 15.06s, 9.00MB read
</span></span><span style=display:flex><span>Requests/sec:   4206.11
</span></span><span style=display:flex><span>Transfer/sec:    612.02KB
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ wrk --latency -t20 -c50 -d15s http://0.0.0.0:8080/api/users/1/raw  <span style=color:#75715e># raw SQL</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Running 15s test @ http://0.0.0.0:8080/api/users/1/raw
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>20</span> threads and <span style=color:#ae81ff>50</span> connections
</span></span><span style=display:flex><span>  Thread Stats   Avg      Stdev     Max   +/- Stdev
</span></span><span style=display:flex><span>    Latency     9.12ms    6.35ms 125.16ms   93.34%
</span></span><span style=display:flex><span>    Req/Sec   233.71     69.49   520.00     71.32%
</span></span><span style=display:flex><span>  Latency Distribution
</span></span><span style=display:flex><span>     50%    7.80ms
</span></span><span style=display:flex><span>     75%   10.08ms
</span></span><span style=display:flex><span>     90%   13.39ms
</span></span><span style=display:flex><span>     99%   38.28ms
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>69947</span> requests in 15.05s, 9.94MB read
</span></span><span style=display:flex><span>Requests/sec:   4647.83
</span></span><span style=display:flex><span>Transfer/sec:    676.30KB
</span></span></code></pre></div><h3 id=revised-benchmarks>Revised benchmarks<a href=#revised-benchmarks class=hanchor arialabel=Anchor>&#8983;</a></h3><p>Now you probably agree that we should run benchmarks with an ORM. Let&rsquo;s design some test vectors:</p><ul><li>FastAPI/Sanic + gino, raw SQL</li><li>FastAPI/Sanic + gino, without baked queries</li><li>FastAPI/Sanic + gino, with baked queries</li><li>Gin + raw SQL</li></ul><p>I&rsquo;ll omit the <a href=https://gist.github.com/kigawas/f97c245efedb286ebfe1deb979a217cb>details</a> here lest Go manias be irritated. In conclusion, the performance (RPS) ranking would be:</p><ul><li>Sanic > FastAPI ~= Gin</li><li>Raw SQL > baked queries &#187; ORM</li><li>Gin, Raw SQL ~= FastAPI, baked queries</li></ul><p>Sanic performs really well, but if automatic request parameter validation or OpenAPI documentation is necessary, FastAPI would be a better (or perhaps the only) choice.</p><h2 id=conclusion>Conclusion<a href=#conclusion class=hanchor arialabel=Anchor>&#8983;</a></h2><p>Asynchronous Python community is growing rapidly and new libraries and frameworks are always emerging. With blazing-fast development efficiency and comparable performance to NodeJS or Golang, asynchronous Python is winning greater popularity in web development steadily.</p><h2 id=trivia>Trivia<a href=#trivia class=hanchor arialabel=Anchor>&#8983;</a></h2><h3 id=gins-annoying-406-errors>Gin&rsquo;s annoying 406 errors<a href=#gins-annoying-406-errors class=hanchor arialabel=Anchor>&#8983;</a></h3><p>If you set <code>wrk -c</code> to <code>200</code>, there may come many HTTP 406 errors when testing Gin. The simplest solution is to set the concurrency to <code>50</code>.</p><h3 id=proper-pool-size-setting>Proper pool size setting<a href=#proper-pool-size-setting class=hanchor arialabel=Anchor>&#8983;</a></h3><p><code>DB_POOL_MAX_SIZE</code> should be greater than concurrent wrk connections to avoid frequent database connection acquirements.</p></div></div><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//kigawas-blog.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div><footer class=footer><div class=footer__inner><div class=copyright><span>Â© 2024 Powered by <a href=http://gohugo.io>Hugo</a></span>
<span>:: Theme made by <a href=https://twitter.com/panr>panr</a></span></div></div></footer><script src=/assets/main.js></script><script src=/assets/prism.js></script></div></body></html>